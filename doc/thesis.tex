%-----------------------------------------------
%  Engineer's & Master's Thesis Template
%  Copyleft by Artur M. Brodzki & Piotr Woźniak
%  Warsaw University of Technology, 2019-2022
%-----------------------------------------------

\documentclass[
    bindingoffset=5mm,  % Binding offset
    footnoteindent=3mm, % Footnote indent
    hyphenation=true    % Hyphenation turn on/off
]{src/wut-thesis}

%\usepackage{setspace}
%\onehalfspacing
%\frenchspacing

\graphicspath{{tex/img/}} % Katalog z obrazkami.

%\usepackage[style=authoryear]{biblatex}
\addbibresource{bibliografia.bib} % Plik .bib z bibliografią

% Do debugowania czy tekst wychodzi poza margines
%\usepackage{showframe}

\usepackage{minted}
\usepackage{mdframed}
\usepackage{float}
\newtheorem{example}{Example}

\mdfdefinestyle{mintedframe}{
    innertopmargin=1mm,
    frametitlebelowskip=0pt,
    frametitleaboveskip=0pt,
    splittopskip=0pt,
    linewidth=0.75pt
}
\surroundwithmdframed[style=mintedframe]{minted}

\mdfdefinestyle{verbatimframe}{
    innertopmargin=1mm,
    frametitlebelowskip=0pt,
    frametitleaboveskip=0pt,
    splittopskip=0pt,
    linewidth=0.75pt
}
\surroundwithmdframed[style=verbatimframe]{verbatim}

%-------------------------------------------------------------
% Wybór wydziału:
%  \facultyeiti: Wydział Elektroniki i Technik Informacyjnych
%  \facultymeil: Wydział Mechaniczny Energetyki i Lotnictwa
% --
% Rodzaj pracy: \EngineerThesis, \MasterThesis
% --
% Wybór języka: \langpol, \langeng
%-------------------------------------------------------------
\facultyeiti    % Wydział Elektroniki i Technik Informacyjnych
\MasterThesis % Praca inżynierska
\langeng % Praca w języku polskim

\begin{document}

%------------------
% Strona tytułowa
%------------------
\instytut{Instytut Automatyki i Informatyki Stosowanej}
\kierunek{Computer Science}
\specjalnosc{Computer Science}
\title{
    Machine learning framework for explainable artificial intelligence models
}
% Title in English for English theses
% In English theses, you may remove this command
\engtitle{
    Machine learning framework for explainable artificial intelligence models
}
% Title in Polish for English theses
% Use it only in English theses
\poltitle{
    Machine learning framework for explainable artificial intelligence models
}
\author{Maciej Falkowski}
\album{329117}
\promotor{dr inż. Mateusz Modrzejewski}
\date{\the\year}
\maketitle

%-------------------------------------
% Streszczenie po polsku dla \langpol
% English abstract if \langeng is set
%-------------------------------------
\cleardoublepage % Zaczynamy od nieparzystej strony
\abstract
The aim of this thesis is to present a system that aims to simplify the analysis of explainable artificial intelligence (XAI) techniques in audio machine learning models.

The proposed system is a framework that integrates selected XAI techniques such as
audioLIME, SHAP (Shapley Additive explanations), and Layer-wise Relevance Propagation (LRP). The framework aims to provide a unified and extensible infrastructure for creating, managing, and visualizing model explanations.

The proposed system is structured using the Model-View-Controller (MVC) design pattern, ensuring modularity, scalability, and separation of concerns. The Model layer encapsulates operations and the machine learning models. The View layer 

defines an intuitive user interface tailored to data scientists and machine learning engineers, enabling interactive exploration of explanation outputs; and the Controller layer manages communication between the model and interface components.

% Ważne by napisać czym praca nie jesy
The aim of the thesis is not to provide 

A key contribution of this work is the formalization of design principles and integration strategies that support multimodal explanations, including both visual and auditory outputs, with a focus on interpretability and usability.

The framework includes visualization modules for displaying saliency maps, relevance heatmaps, and feature contribution plots, dynamically generated based on user queries and model outputs. In addition, user roles and interaction paradigms are defined to accommodate different levels of expertise, ensuring accessibility for both novice and expert users. The evaluation of the system demonstrates its effectiveness in improving interpretability and user understanding of complex model behaviors.

This work lays the groundwork for future research and development in human-centric AI systems, offering a flexible foundation for building transparent and trustworthy machine learning applications.
\keywords XXX, XXX, XXX

%----------------------------------------
% Streszczenie po angielsku dla \langpol
% Polish abstract if \langeng is set
%----------------------------------------
%\clearpage
%\secondabstract \kant[1-3]
%\secondkeywords XXX, XXX, XXX

\pagestyle{plain}

%--------------
% Spis treści
%--------------
\cleardoublepage % Zaczynamy od nieparzystej strony
\tableofcontents

%------------
% Rozdziały
%------------
\cleardoublepage % Zaczynamy od nieparzystej strony
\pagestyle{headings}

% #############################################
%
% Rozdział 1 - Introduction
%
% #############################################
\clearpage % Rozdziały zaczynamy od nowej strony.
\section{Introduction} \label{ch:introduction}

% Akapit z cytatem
\lipsum[1] \cite{goossens93}

% Przykładowy obrazek
\begin{figure}[!h]
    % Wyrównanie obrazka, szerokość i plik
    % Zamiast width można też użyć height, etc.
    \centering \includegraphics[width=0.5\linewidth]{logopw.png}
    % Podpis umieszczamy pod obrazkiem
    % znacznik \caption służy również do wygenerowania numeru obrazka
    \caption{Tradycyjne godło Politechniki Warszawskiej}
    % \label pozwala odwołać się do obrazka w innych miejscach za pomocą \ref
    % odwołanie \ref renderuje się jako numer obrazka,
    % dlatego zawsze najpierw używaj \caption a potem \label
    \label{fig:tradycyjne-logo-pw}
\end{figure}

% \ref wyrenderuje się jako 'Reference to image 1.1'
\lipsum[2] Reference to image \ref{fig:tradycyjne-logo-pw}.

% Lista punktowana
% Parametr label ustawia symbol punktora
\begin{itemize}
    \item Item 1:
    \begin{itemize}[label=---]
        \item item 1.1;
        \item item 1.2;
    \end{itemize}
    \item Item 2;
    \item Item 3.
\end{itemize}

\lipsum[3]

% Lista numerowana w formacie 1.a).ii
% Tutaj również można stosować \label
\begin{enumerate}
    \item Item 1:
    \begin{enumerate}
        \item item 1.1;
        \item item 1.2:
        \begin{enumerate}
            \item item 1.2.1;
            \item item 1.2.2;
        \end{enumerate}
        \item item 1.3;
    \end{enumerate}
    \item Item 2;
    \item Item 3.
\end{enumerate}

% Przypis dolny \footnote
\lipsum[4] Lorem ipsum dolor sit amet\footnote{Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat.}, consectetur adipiscing elit.

% Przykładowa tabela: wyśrodkowana i renderowana
% w miejscu wstawienia: !h = !h[ere]
% Domyślnie tabele trafiają na górę strony
\begin{table}[!h] \centering
    % Podpis tabeli umieszczamy od góry
    \caption{Przykładowa tabela.}
    \label{tab:tabela1}

    % Tabela z trzema kolumnami:
    % dwie wyrównanie do środka [c], a ostatnia do prawej [r]
    % szerokość kolumn automatyczna (równa szerokości tekstu)
    \begin{tabular}{| c | c | r |} \hline
        Kolumna 1       & Kolumna 2 & Liczba \\ \hline\hline
        cell1           & cell2     & 60     \\ \hline
        cell4           & cell5     & 43     \\ \hline
        cell7           & cell8     & 20,45  \\ \hline
        % Komórka o szerokości dwóch kolumn, wyrównana do prawej
        % Przypisy dolne w tabelach wstawiamy przez \tablefootnote
        \multicolumn{2}{|r|}{Suma\tablefootnote{Table footnote.}} & 123,45 \\ \hline
    \end{tabular}

\end{table}

Lorem ipsum dolor sit amet.

% #############################################
%
% Rozdział 2 - Analiza problemu
%
% #############################################
\clearpage % Rozdziały zaczynamy od nowej strony.
\section{Problem analysis} \label{ch1:probAnalysis}

This chapter provides an overview of terminology and methods used in the thesis,
which describes essentials of machine learning explanations, description of explanation methods used in the thesis which are audioLIME, LRP, SHAP, and software engineering principles used for designing a framework for audio machine learning explanations.

\subsection{Black box interpretation of ML predictors} % Why explanation framework for audio - the problem
\subsubsection{Why explanation framework for audio - the problem}

\subsection{Similar solutions}

To the best of our knowledge this is the ...

\subsection{Selection of methodology - overview of framework, monolithic UI etc.}

\subsection{Framework definition}
\subsubsection{Definition}
\subsubsection{Modularity}
\subsubsection{Dependency injection}

\subsection{Definition of user}

\subsection{Definition of ML explanation}
\subsubsection{Locality-awareness}
\subsubsection{Model-agnostic}

\subsection{Audio processing}
\subsubsection{Waveform representation}
\subsubsection{Mel-spectogram}

\subsection{Model explanation}
\subsubsection{definition}
\subsubsection{Locality-awareness}

\subsection{Selection of explanation methods for framework}
\subsubsection{Criteria - interpretability, attribution, model-agnostic}
\subsubsection{AudioLIME} \label{ch1:audioLIME}
\subsubsection{Shapley Additive Explanations} \label{ch1:ShapMethod}
\subsubsection{Layer-wise Relevance Propagation} \label{ch1:LrpMethod}

\subsection{Selection of model for integration}
\subsubsection{Criteria - practicality}
\subsubsection{State-of-art Music Models}
\subsubsection{Paans}
\subsubsection{Paast}
\subsubsection{Handmade Gtzan}

\subsection{ML Explanation framework overview}
\subsubsection{Framework components - library, UI, terminal command}

\subsection{Visualizing ML Explanation framework overview} 

\subsection{Model-View-Controller} \label{ch1:ModelViewController}
\subsubsection{Architecture of Model-View Controller}
\subsubsection{Characteristic of Model, View and Controller}
\subsubsection{Separation of operations on data and visualization}

% #############################################
%
% Rozdział 3 - Requirements and tools (może Framework requirements?)
%
% #############################################
\clearpage % Rozdziały zaczynamy od nowej strony.
\section{Requirements and tools} \label{ch:reqrTools}

        This chapter defines and formalizes requirements that the project must actualize
    to meet the objective of the thesis, including software and behavioral requirements.
    The chapter starts with a definition of functional and non-functional requirements,
    followed by an overview of software requirements and tools used in the thesis.

\subsection{Functional requirements}

    The functional requirements seek to define how a framework should behave to its user.
    For clarity the requirements are divided based on the software component of the framework which
    in framework's case are library, user web interface, and terminal helper tool.

% Wymagania interfejsu, backend serwera, UI
\subsubsection{Library application programming interface requirements}
    \begin{enumerate}[itemsep=1\baselineskip]

    \item \textbf{Provide user model injection}

        The library API must enable users to create adapters for their classes allowing them to inject operations on
    their data into the framework. Users may implement custom model adapters by extending the provided base
    classes. This enables integration of various audio model architectures with the explanation
    framework.

    \item \textbf{Provide explanation interface for model adapters}

        The library API must offer base classes for implementing a given explanation method.
    Each adapter type must define specific methods required for the corresponding explanation algorithm,
    including LIME, SHAP, or LRP, ensuring a consistent interface for different explanation methods.

    \item \textbf{Explanation method Selection}

        The library API must offer users the ability to choose which explanation methods are displayed in the view.
    Users can select from available explainers including LIME, SHAP, and LRP through library API or through
    command-line arguments in case when using a helper tool. This allows users to focus on specific explanation
    approaches relevant to their use case.

    \item \textbf{Support necessary audio format}

        The library API must support user audio input provided in \texttt{.wav} and \texttt{.mp4} formats.
    Audio should be automatically converted to appropriate tensor formats for model processing.

    \item \textbf{Provide interface for view classes}

        The library API must offer a base interface for implementing views which will fulfill
    the requirement of modularity and allow a system to support multiple view types.

    \item \textbf{Context Management}

        The library API must define a context that serves to store and save the current explanation progress.
    The context class manages working directories, file operations, and explanation state throughout the process.
    Context provides centralized access to resources and maintains consistency across different explanation phases.

    \item \textbf{Interface for prediction class information}

        The library should offer an interface enabling users to inject prediction class information.
    This information is essential for proper explanation interpretation and visualization.
    The system should support label retrieval dynamically depending on whether the user provided
    support for their user-defined model adapters.

    \item \textbf{Support for selected explanation methods}

        The library API must provide explanation methods selected for the thesis, such as LIME, SHAP, and LRP.
    These methods should be implemented as classes, and they also serve as controllers within
    the Model-View-Controller pattern and coordinate between model adapters, explanation algorithms, and view components. They encapsulate the complete explanation workflow from input processing to result visualization.

    \item \textbf{Support for web interface view}

        The library API must define web server view classes that manage file serving and web-based user interface.
    Web server components handle HTTP requests and serve explanation results through a user interface.

    \item \textbf{Ensure persistent result storage}

        The library API must ensure persistent storage of user results on disk to prevent
    data loss. The context system should provide this by saving explanation artifacts to
    the working directory. This will enable users to archive explanation outputs across 
    multiple sessions.
    
    \end{enumerate}

\subsubsection{User web interface requirements}
    \begin{enumerate}[itemsep=1\baselineskip]
    %\vspace{\baselineskip}
    \item \textbf{Separate tab for each explanation result}

            The user interface must aggregate the results of each explanation method in separate tabs to organize
        outcomes and enable switching between them. Each explanation method, which is LIME, SHAP, or LRP,
        should get its dedicated tab. This should allow users to easily navigate different explanation approaches
        to compare results. The sidebar should provide a structured view of all generated explanations in a single
        interface and allow you to switch between them.

    \item \textbf{Display original audio playback}

        The user interface must display the original audio track that serves as input for explanations across all
    explanation methods. The interface must enable audio playback functionality, including play/pause controls and
    waveform visualization. Users can listen to the original audio while examining explanation results for better
    context understanding. The waveform display provides a visual representation of the audio signal structure.

    \item \textbf{Visualize LIME explanation result}

        The user interface must display LIME explanation result as playable audio.
    Users should be able to listen to specific audio segments that contributed most significantly
    to the model's prediction. This enables an intuitive understanding of which temporal parts of
    the audio influenced the model's decision. The width of the explained audio visualization
    should be aligned with the original audio.

    \item \textbf{Provide version information}

        The user interface must display information about the library version so that users may verify which
    version of a library they are currently using. Such information may prove to be useful,
    for example, for troubleshooting.

    \item \textbf{Display notification and error information}

        The user interface must display notifications about errors or other information in a dedicated information
    panel. The notification system provides user feedback for processing status, errors, warnings,
    and completion messages. Users receive clear communication about the system state and any issues that
    require attention. The dedicated panel ensures important messages are prominently displayed without
    disrupting the main workflow.

    \item \textbf{Visualize attribution intensity}

        The user interface must show plot of attribution intensity of user's input audio
    for both SHAP and LIME explanations. The attribution scores given to various audio input segments are displayed in these plots. This enables users to determine which audio signal regions had the biggest impact on the model's prediction.

    \item \textbf{Display of user's input overlayed with attribution}

        The user interface must display attribution overlaid on user's input for both SHAP and LIME explanations.
    Attribution values are visualized as color heatmaps on the user's spectrogram which enables a user to
    understand which frequency components at a given time interval influenced the model's decision.
    This method works very well when the input provided to the model is a spectrogram.

    \item \textbf{Display prediction classes of user's model}

        The user interface must display optional model label descriptions when provided by the user's model adapter.
    The interpretability of explanation visualizations is improved by label information.

    \end{enumerate}

\subsubsection{Terminal application requirements}
    Framework must provide a terminal-application tool for launching supported models on framework's explanation method with input provided by the user. The tool then will implement a typical usage scenario:
    \begin{enumerate}
        \item User input is converted from a waveform input into model's type which is either tensor of input samples or spectrogram type.
        \item The tool defines a necessary model adapter,
    \end{enumerate}

    \begin{enumerate}[itemsep=1\baselineskip]

    \item \textbf{Provide selection of one or more explanation method}

        The application must enable users to select one or more explanation methods offered by the framework which are LIME, SHAP, or LRP.

    \item \textbf{Provide selection of audio model}

            The application must enable users to select from models implemented within the framework that they
        intend to use. 

    \item \textbf{Provide selection of visualization method}

        The application must enable users to select the visualization method implemented in the framework.
    Users can choose between web-based visualization and disabled visualization.

    \item \textbf{Provide selection of working directory}

    The application must enable users to select a folder as the working directory or create a default when not provided by the user.

    \end{enumerate}

\subsection{Non-functional requirements} \label{ch:NonFuncRequirements}

    The implementation of an audio XAI framework must meet several criteria
    top ensure proper behavior for the user and quality criteria.
    The most important criteria are modularity, usability, and persistency.

\begin{description}
    \item \textbf{Modularity}

         The project thesis aims to provide a general and extensible audio explanation framework. The system must be 
    designed with a modular structure, where key components such as explanation methods, model adapters, and view renderers
    are implemented as independent modules. For that, the system must adhere to the pattern principles of Model-View-
    Controller architecture as discussed in <Sec. TODO> This modularity allows for the seamless integration of new 
    functionalities, such as adding additional explanation algorithms or supporting new audio models, without requiring 
    modifications to the core of the system.

    \item \textbf{Reliability}

        The system must behave stably and predictably during normal operation. During regular operation, the system has to
    display stable and predictable behavior. The user interface, audio processing pipelines, and explanation methods must
    all gracefully handle runtime errors and invalid inputs. Errors must be properly logged, and informative feedback must
    be sent to the user without crashing. To avoid data loss, intermediate and final outputs need to be saved consistently.

    \item \textbf{Usability}

        The framework library and web user interface must follow intuitive design principles, including consistent
    navigation, clear labeling, and visual clarity of explanation results. The use of separate tabs for different 
    explanation methods ensures that users can focus on one explanation at a time while easily switching between views. 
    Notifications and status indicators must be visible and should inform a user about the behavior of the interface. In 
    addition, the command-line application helper tool must be a fast way of testing the library implementation and environment setup.

\end{description}

\subsection{Tools specification} \label{ch:ch3LabelSpec}
\begin{description}
\item \textbf{PyTorch}

A comprehensive open-source machine learning framework that provides exceptional flexibility for building and training neural networks with dynamic computational graphs. PyTorch offers seamless GPU acceleration capabilities enabling efficient training of complex deep learning models on large datasets. The framework provides extensive libraries of pre-built components and optimizers that accelerate development while maintaining a pythonic interface. PyTorch has become the preferred framework for research due to its intuitive debugging experience and strong community support.

\item \textbf{librosa}

A specialized Python library for music and audio signal processing that provides comprehensive tools for analyzing sound data through various time-frequency transforms. Librosa offers advanced capabilities for rhythm analysis, beat detection, and feature extraction of key acoustic characteristics commonly used in machine learning pipelines. The library integrates smoothly with numerical computing libraries while supporting various audio formats with built-in resampling capabilities. Librosa emphasizes reproducible research with transparent implementations of audio algorithms complemented by excellent documentation.

\item \textbf{torchaudio}

A domain-specific library built on PyTorch that provides GPU-accelerated tools for audio processing tasks in deep learning applications. TorchAudio offers seamless integration with PyTorch's autograd system, enabling gradient-based training with audio feature extractors as differentiable components. The library includes specialized audio augmentation techniques and pre-trained models for common audio tasks with a consistent tensor-based API. TorchAudio ensures compatibility with PyTorch's ecosystem and is actively maintained with regular updates incorporating state-of-the-art techniques.

\item \textbf{pytest}

A sophisticated testing framework for Python that emphasizes simplicity with a minimalist syntax for writing tests and a powerful fixture system for managing dependencies. Pytest's parameterization features enable running tests with multiple inputs while providing detailed assertion introspection to quickly identify issues. The framework's plugin architecture has fostered a rich ecosystem of extensions for specialized testing needs including coverage analysis. Pytest supports both unit and functional testing with automatic test discovery and comprehensive reporting features.

\item \textbf{matplotlib}

A comprehensive data visualization library for Python that has become the standard for creating publication-quality figures and interactive visualizations. Matplotlib offers exceptional flexibility through its object-oriented API, allowing precise control over every aspect of plots for creating complex custom visualizations. The library supports an extensive range of plot types from basic line graphs to specialized visualizations suitable for diverse data representation needs. Matplotlib integrates seamlessly with NumPy and pandas while providing robust support for mathematical expressions through LaTeX rendering.

\item \textbf{captum}

An interpretability library built specifically for PyTorch that implements state-of-the-art algorithms for explaining decisions made by deep learning models. Captum provides unified implementations of gradient-based attribution methods that reveal feature importance across various model architectures at multiple granularities. The library implements advanced visualization techniques for different data modalities, rendering attributions as heatmaps for images and waveforms for audio. Captum's attribution methods support batch processing and GPU acceleration with a consistent API that works across different model architectures.

\item \textbf{React}

A declarative JavaScript library that has revolutionized user interface development through its component-based architecture and efficient virtual DOM rendering system. React promotes unidirectional data flow that makes application state changes predictable while its JSX syntax combines JavaScript with HTML-like templates for creating reusable components. The library's robust ecosystem includes state management solutions, routing libraries, and testing frameworks that address common development challenges. React's composition-focused design encourages creation of small, focused components that can be combined to build complex interfaces while promoting code reuse.
\end{description}

% #############################################
%
% Rozdział 4 - External specification
%
% #############################################
\clearpage % Rozdziały zaczynamy od nowej strony.
\section{External specification} \label{ch:externalSpec}

\subsection{Installation process overview}
\subsubsection{Installation steps}

\subsection{Command-line tool for simple explanations}

\subsection{Web interface for explanation}
\subsubsection{Initalizing web interface}
\subsubsection{Displaying LIME results}
\subsubsection{Displaying LRP results}
\subsubsection{Displaying SHAP results}
\subsubsection{Displaying software warning}
\subsubsection{Version information}

% #############################################
%
% Rozdział 5 - Framework implementation
%
% #############################################
\clearpage % Rozdziały zaczynamy od nowej strony.
\section{Framework implementation} \label{ch:implementation}

    The following chapter contains an overview of the architecture and implementation details of the explanation framework. It briefly discusses each of the system's components by providing
    a walk-through of each step of the framework's explanation pipeline.

\subsection{Software architecture overview}

    The architecture of the project consists of three main components that are library, web interface, and command-line helper script.
    These component implement all steps of a full-pipeline from prereprocessing
    user's input up to visualizing explanation results as discussed in
    %\ref{fig:PipelineArchitecture}. TODO

\begin{enumerate}
    \item \textbf{Library} - Provides the main logic and implementation. It is interfacing directly with a user and
    provides the necessary tools for the execution of an explanation. This includes interfaces for the creation of 
    adapters for users' models, logic implementing supported explanation types, visualization of explanations that 
    include a frontend web interface, and helper utilities.

    \item \textbf{Web interface} - Defines a main visual view for the observation of the explanations' results. It is
    composed of two parts which the first is a backend server that serves the explanation results to the frontend part
    through the HTTP protocol. The frontend part then requests the required data from the backend server and visualizes
    it in the form of a browser page. The communication process between user application and framework is shown in
    \ref{fig:CommunicationArchitecture}.

    \item \textbf{Command-line helper script} - It is a toolchain's helper script and serves the purpose of quickly 
    launching a typical usage type of the library, which is loading an input audio file and then launching a chosen set 
    of explanations on the chosen library's provided model.
\end{enumerate}

\begin{figure}[h!] % TODO: h! musi być wyłączone
    \centering
    \includegraphics[width=15cm]{comm.jpg}
    \caption{Communication scheme between user application and frontend.}
    \label{fig:CommunicationArchitecture}
\end{figure}

\subsection{Project structure}

    The project’s source code is grouped in multiple directories grouping similar implementations. They contain an implementation of each of the framework’s pipeline phases
    and unit test definitions for them.

\begin{itemize}[itemsep=1\baselineskip]
	\item \textbf{audioLIME/} - Contains implementation of audioLIME explanation method,
	\item \textbf{AudioLoader/} - Provides utilities for loading and preprocessing audio files,
	\item \textbf{Explainers/} - Contains explainer classes for LIME, SHAP, and LRP methods,
	\item \textbf{pylibxai\_explain.py} - Main command-line entry point for running explanations on audio models,
	\item \textbf{Interfaces/} - Defines abstract base classes and interfaces for model adapters and views,
	\item \textbf{LRPExplainer/} - Contains Layer-wise Relevance Propagation  explainer implementation,
	\item \textbf{model\_adapters/} - Implements adapter classes for integrating different audio models with the framework,
	\item \textbf{models/} - Contains pretrained model files and checkpoints for supported audio models,
	\item \textbf{pylibxai\_context/} - Implements context management for storing explanation state and working directories,
	\item \textbf{pylibxai\_server/} - Contains web server implementation for serving explanation results through HTTP,
	\item \textbf{pylibxai-ui/} - Frontend React application providing web-based user interface for visualization,
	\item \textbf{ShapExplainer/} - Contains SHAP (Shapley Additive Explanations) explainer implementation.
\end{itemize}

\subsection{Model-View-Controller implementation overview}

\begin{figure}%[h!] % TODO: h! musi być wyłączone
    \centering
    \includegraphics[width=15cm]{class_diagram.png}
    \caption{Library class diagram.}
    \label{fig:ClassDiagram}
\end{figure}

    The thesis utilizes Model-View-Controller (MVC) architectural pattern (Sec. \ref{ch1:ModelViewController}) to obtain extendable architecture that satisfies one of core requirements of the thesis that is modularity as discussed in Sec. \ref{ch:NonFuncRequirements}. This allows a framework to be easily extandable with a new explanation types, model predictors, and views separating these three from each other so that the developer might work on one of these exclusively.

    The Model-View-Controller is implemented using
    the following classes visible in the class diagram \ref{fig:ClassDiagram}. The implementation and details of these classes are discussed later in the chapter:
    \begin{description}
        \item[Model] The function of the model in the framework is realized using adapter classes for user models, such as \texttt{SotaMusicModelsAdapter} (Sec. TODO) or \texttt{PaansAdapter} (Sec. TODO). These classes operate on user data passed to them from controller classes, performing data manipulation, which is an inference in this case. The interface for these classes is discussed in Sec. TODO,

        \item[View] The function of view in the framework is realized using classes such as \texttt{WebView} or \texttt{DebugView}. These classes receive explanation results specified in the \texttt{Context} class as required by the \texttt{ViewInterface} class and process them to display the results to the user,

        \item[Controller] The purpose of this part is to pass the user’s input into the model
        classes for data manipulation and to later pass the results of data manipulation into 
        the view. This functionality is achieved by classes implementing explainers' logic, 
        such as \texttt{LimeExplainer} or \texttt{ShapExplainer}.

    \end{description}

\subsection{Interfaces for model adapters}

    Model adapters require a set of interfaces that specify the required behavior that a user
    must fulfill to make their model work properly within the framework. For that reason, the 
    library provides an interface for required explanation methods to perform a given 
    explanation that specifies behavior
    between a given explainer class and the user’s model adapter. This provides enough 
    granularity to the interface so that a user may freely decide which explanation method 
    they would like to provide support for.
    Interfaces for model adapters are implemented with the use of
    Python’s \mintinline{py}{ABC} module \cite{pythonABC}, which allows defining abstract 
    base classes for other classes. Every interface method is annotated 
    \mintinline{py}{@abstractmethod}, requiring a user to define it when performing inheritance, or it throws a \mintinline{py}{TypeError} exception otherwise.
    
\subsubsection{LIME method adapter}

    Adapter for LIME method (\ref{ch1:audioLIME}) defines the interface that the user's model needs to satisfy to be able to launch \texttt{audioLIME} explanation on it.
    This interface requires from user defining a single method \mintinline{py}{get_lime_predict_fn(self)}
    that must return a \mintinline{py}{np.array}.

\begin{figure}%[h]
\begin{minted}[numbersep=12pt, fontsize=\footnotesize, xleftmargin=12pt, linenos, mathescape]{py}
from abc import ABC, abstractmethod
import numpy as np

class LimeAdapter(ABC):
    """Abstract base class for LIME (Local Interpretable
       Model-agnostic Explanations) adapters"""
    @abstractmethod
    def get_lime_predict_fn(self) -> np.array: pass
    """Returns a function that takes an audio input and
       returns the model's prediction for that input."""
\end{minted}
\caption{Class definition of \texttt{LimeExplainer}.}
\label{fig:LimeAdapter}
\end{figure}

\subsubsection{SHAP method adapter}

    In the same way, adapter for SHAP method (\ref{ch1:ShapMethod}) defines the interface that the user's model needs to satisfy to be able to launch Shapley-Additive explanation on it.
    This interface requires from user defining a single method \mintinline{py}{get_shap_predict_fn(self)}
    that must return an \mintinline{py}{np.array}.

    Additionally, SHAP interface requires defining a \mintinline{py}{shap_prepare_inference_input} method that serves a purpose of additionally preprocessing data for a given model as shown in \ref{fig:ShapAdapter}.
    This is required as interface for explainers accept user's waveform input but they do expect an input which is the same as model's input which may be either waveform or a spectogram which requires additional conversion.

\begin{figure}%[h]
\begin{minted}[numbersep=12pt, fontsize=\footnotesize, xleftmargin=12pt, linenos, mathescape]{py}
class ShapAdapter(ABC):
    """Abstract base class for SHAP (SHapley Additive exPlanations)
       adapters"""
    @abstractmethod
    def get_shap_predict_fn(self) -> np.array: pass
    """Returns a function that takes an audio input and returns
    the model's prediction for that input."""

    @abstractmethod
    def shap_prepare_inference_input(self, x: torch.Tensor) \
        -> torch.Tensor: pass
    """Returns a function that takes an audio input
    and returns the model's prediction for that input."""
\end{minted}
\caption{Class definition of \texttt{ShapExplainer}.}
\label{fig:ShapAdapter}
\end{figure}

\subsubsection{LRP method adapter}

    The last method adapter for LRP method (\ref{ch1:LrpMethod}) also requires the user to define a single method \mintinline{py}{get_lime_predict_fn(self)} that must return \mintinline{py}{nn.Module}. This return type is required as Captum's LRP implementation takes it as an input.

    \begin{example}
        An exemplary implementation of LrpAdapter for an exemplary user's adapter \texttt{MyModelAdapter}
        is shown in \ref{fig:UserAdapterExample}.
    \end{example}

\begin{figure}%[h]
\begin{minted}[numbersep=12pt, fontsize=\footnotesize, xleftmargin=12pt, linenos, mathescape]{py}
from pylibxai.Interfaces import LrpAdapter

class MyModelAdapter(LrpAdapter):
    def __init__(self, model, device):
        self.model = model
        self.device = device

    def get_lrp_predict_fn(self):
        class MyModelWrapper(torch.nn.Module):
            def __init__(self, model):
                super(MyModelWrapper, self).__init__()
                self.predictor = predictor
                self.device = device

            def forward(self, x):
                self.predictor.model.eval()
                return self.predictor.model(x)

        return MyModelWrapper(self.predictor, self.device)
\end{minted}
\caption{A sample implementation of \texttt{LrpAdapter} for the exemplary \texttt{MyModelAdapter} class.}
\label{fig:UserAdapterExample}
\end{figure}


\begin{figure}%[h]
\begin{minted}[numbersep=12pt, fontsize=\footnotesize, xleftmargin=12pt, linenos, mathescape]{py}
class LrpAdapter(ABC):
    """Abstract base class for LRP (Layer-wise Relevance Propagation)
       adapters"""
    @abstractmethod
    def get_lrp_predict_fn(self)\
    \-> nn.Module: pass
    """Returns a function that takes an audio input and
       returns the model's prediction for that input."""
\end{minted}
\caption{Class definition of \texttt{LrpAdapter}.}
\label{fig:LrpAdapter}
\end{figure}

\subsection{Model adapter implementation}

\

\subsubsection{GtzanCNN model adapter}
\subsubsection{SOTA model adapter}
\subsubsection{Paans model adapter}

\subsection{Explainer classes implementation}

Explanation methods are implemented as separate classes including \texttt{LimeAdapter}, \texttt{ShapExplainer}, and \texttt{LrpAdapter}.
The purpose of these classes is to implem TODO

These classes serves a purpose of controllers as part of Model-View-Controller pattern so their purpose include managing 


\subsubsection{LIME explainer}
\subsubsection{SHAP explainer}
\begin{figure}%[h]
\begin{minted}[numbersep=12pt, fontsize=\footnotesize, breaklines, xleftmargin=12pt, linenos, mathescape]{py}
class ShapExplainer:
    def __init__(self, model_adapter, context, device, view_type=None):
        self.model_adapter = model_adapter
        predict_fn = model_adapter.get_shap_predict_fn()
        self.explainer = IntegratedGradients(predict_fn)
        self.device = device
        self.attribution = None
        self.delta = None
        self.context = context
        self.view_type = view_type
        if view_type == ViewType.WEBVIEW:
            self.view = WebView(context, port=9000)
        elif view_type == ViewType.DEBUG:
            pass

    def explain_instance(self, audio, target, background=None):
        pass
    
    def explain_instance_visualize(self, audio, target, type=None, background=None, attr_sign='positive'):
        pass

    def get_attribution(self):
        pass

    def get_smoothed_attribution(self):
        pass
    
    def explain(self, audio, target):
        pass
\end{minted}
\caption{Class definition of \texttt{ShapExplainer}.}
\label{fig:ShapExplainer}
\end{figure}
\subsubsection{LRP explainer}

\subsection{Context class definition}

The \texttt{PylibxaiContext} class manages the data and encapsulates the data saving process.
It is an important bridge between model and view classes, formalizing how explanation results
are saved and accessed through a framework.
The class also implements the requirement \textit{Context Management} and \textit{Ensure persistent result storage} as described in Sec. (\ref{ch:NonFuncRequirements}), fully encapsulating the process of
saving the explanation results into the persistent storage. For the simplicity of design and also the purpose of serving
explanation result to the web frontend as discussed later in \ref{ch:ch5WebFrontend},
the implementation of this class saves all explanation results as files in a tree structure in a given working directory.

\begin{example}
    An exemplary implementation of \texttt{write\_attribution} method of \\
    \texttt{PylibxaiContext} class. The method saves an attribution of the explanation to a file in \texttt{JSON} format
    as shown in Fig. \ref{fig:WriteAttributionMethod}.
\end{example}

\begin{figure}%[h]
\begin{minted}[numbersep=12pt, fontsize=\footnotesize, breaklines, xleftmargin=12pt, linenos, mathescape]{py}
def write_attribution(self, smoothed_attribution, suffix):
    path = os.path.join(self.workdir, suffix)
    with open(path, 'w') as f:
        json.dump({
            "attributions": smoothed_attribution.tolist(),
        }, f, indent=4)
\end{minted}
\caption{The implementation of \texttt{write\_attribution} method.}
\label{fig:WriteAttributionMethod}
\end{figure}

\begin{figure}%[h]
\begin{minted}[numbersep=12pt, fontsize=\footnotesize, breaklines, xleftmargin=12pt, linenos, mathescape]{py}
class PylibxaiContext:
    def __init__(self, workdir):
        self.workdir = workdir
        # [...]
    
    def write_plt_image(self, fig, suffix): pass # [...]
    
    def write_attribution(self, smoothed_attribution, suffix): pass # [...]

    def write_label_mapping(self, labels, suffix): pass # [...]
    
    def write_audio(self, audio, suffix, *args, **kwargs): pass # [...]
\end{minted}
\caption{Class definition of \texttt{PylibxaiContext}.}
\label{fig:PylibxaiContext}
\end{figure}

The \texttt{PylibxaiContext} class contains the following fields, as shown in its definition in Fig. \ref{fig:PylibxaiContext}:

\begin{itemize}
    \item \mintinline{py}{self.workdir} - the field holds a path to the working directory in which explanation results will be saved,
    \item \mintinline{py}{write_plt_image(self, fig, suffix)} - it handles saving the results of Matplotlib's (Sec. \ref{ch:ch3LabelSpec}) generated image,
    \item \mintinline{py}{write_attribution(self, smoothed_attribution, suffix)} - it handles saving explanation's attribution,
    \item \mintinline{py}{write_label_mapping(self, labels, suffix)} - it handles saving the mapping of labels into their indexes,
    \item \mintinline{py}{write_audio(self, audio, suffix, *args, **kwargs)} - it handles saving of an audio file,
\end{itemize}

\subsection{View classes}

The purpose of view classes is to present explanation results to the user in a readable form
according to Model-View-Controller pattern. The framework is implemented with modularity as a goal
and allows multiple views defined implementing \texttt{ViewInterface} interface.
The framework is implemented with modularity as a goal and allows multiple views
defined by implementing \texttt{ViewInterface} interface that defines how explanation
classes should be implemented in the framework.
This interface \texttt{ViewInterface} requires a user to define the necessary
methods required to initialize, start, and stop the given view as shown in Fig. \ref{fig:ViewType}.

\begin{itemize}
    \item \mintinline{py}{__init__(self, context, port)} - A given view is initialized with a provided context class.
    The view then may utilize the accumulated results of explanation in that class and present them to the user,

    \item \mintinline{py}{start(self)} - The start method is responsible for launching the given view. In the case of \texttt{WebView},
    it starts the backend and frontend servers. For \texttt{DebugView} it generates a terminal debugging logs showing based on 
    explanation results,
    
    \item \mintinline{py}{stop(self)} - The stop method is responsible for stopping and cleaning the execution of a given view class. It is required though it logic may be empty when there is nothing to stop as in case of \texttt{DebugView} class.
\end{itemize}

\begin{figure}%[h]
\begin{minted}[numbersep=12pt, fontsize=\footnotesize, breaklines, xleftmargin=12pt, linenos, mathescape]{py}
class ViewInterface(ABC):
    """Abstract base class for View Interface
    """
    @abstractmethod
    def __init__(self, context, port):
        self.context = context
        self.port = port

    @abstractmethod
    def start(self) -> None: pass

    @abstractmethod
    def stop(self) -> None: pass    
\end{minted}
\caption{Class definition of \texttt{ViewInterface}.}
\label{fig:ViewInterface}
\end{figure}

Every view class defined in a framework must have an entry in enumeration \texttt{ViewType}.
For \texttt{WebView} there is an enumeration \mintinline{py}{DEBUG} provided, for \texttt{DebugView}
it is \mintinline{py}{DEBUG} as shown in Fig. \ref{fig:ViewType}.

\begin{figure}%[h]
\begin{minted}[numbersep=12pt, fontsize=\footnotesize, breaklines, xleftmargin=12pt, linenos, mathescape]{py}
class ViewType(IntEnum):
    """Enum-like class for View Types"""
    WEBVIEW = 1
    DEBUG = 2
    NONE = 2
\end{minted}
\caption{Class definition of \texttt{ViewType}.}
\label{fig:ViewType}
\end{figure}

\subsubsection{Web view}

The \texttt{WebView} implementation provides the main visualization of the explanation results
in the form of a web page. Its implementation only starts the underlying backend and frontend servers
in separate processes using Python's subprocess module.  The class implements the View interface to be later used within a framework. The definition of \texttt{WebView} is visible in Fig. \ref{fig:WebView}.

The whole startup process of the WebView contained in the \mintinline{py}{setup()} method contains the following steps:
\begin{enumerate}
    \item The startup procedure starts with the creation of a backend server using the function  \\
        \mintinline{py}{run_file_server(self.context.workdir, self.port)}.
        It takes the path of \\ the working directory from a given instance of the \texttt{Context} class
        and start a file serving server using Python's \mintinline{py}{socketserver.TCPServer} class.
        The implementation of file server is discussed later in Sec. \ref{ch5:FileServer},
    \item In the next step, the frontend server is initialized with the use of the Vite \cite{ViteDOC} tool,
        which it is based on. The \texttt{subprocess.Popen} argument takes the
        Vite command startup arguments as \mintinline{py}{['npm', 'run', 'dev']} that is run in the current working directory where the implementation of the frontend source code is placed, which is \mintinline{py}{cwd=self.vite_dir}. Additional parameters for the frontend web server are passed through the environmental variables, such as a port number that is passed to the frontend through the \mintinline{py}{'VITE_PYLIBXAI_STATIC_PORT'} environmental variable.
    
\end{enumerate}

\begin{figure}%[h]
\begin{minted}[numbersep=12pt, fontsize=\footnotesize, breaklines, xleftmargin=12pt, linenos, mathescape]{py}
class WebView(ViewInterface):
    def __init__(self, context, port=9000):
        super().__init__(context, port)
        self.vite_dir = get_install_path() / "pylibxai" / "pylibxai-ui"
        self.server = None
        self.vite_process = None

    def start(self):
        # Start the file server
        self.server = run_file_server(self.context.workdir, self.port)
        # Start the Vite UI
        env = os.environ.copy()
        env['VITE_PYLIBXAI_STATIC_PORT'] = str(self.port)
        print(f"Vite UI directory: {self.vite_dir}")
        self.vite_process = subprocess.Popen(
            ['npm', 'run', 'dev'],
            cwd=self.vite_dir,
            env=env,
            stdout=sys.stdout,
            stderr=sys.stderr,
            shell=True
        )
        print(f"Vite UI launched at http://localhost:{self.port}/ (UI dev server running)")

    def stop(self):
        if self.vite_process:
            self.vite_process.terminate()
            self.vite_process.wait()
            print("Vite UI process terminated.")
        if self.server:
            self.server.shutdown()
            print("File server stopped.")
\end{minted}
\caption{Class definition of \texttt{WebView}.}
\label{fig:WebView}
\end{figure}
 
\subsubsection{Debug View}

\subsection{Web frontend implementation} \label{ch:ch5WebFrontend}

% Figure: Communication scheme Backend <-> Frontend

\subsubsection{File server backend} \label{ch5:FileServer}

%\begin{example}
% Show that a path workdir/lrp/attribution.json will be under path /lrp/attribution.json    
%\end{example}

\subsubsection{Frontend UI class}

\subsection{Frontend web interface view implementation}
%\subsubsection{Main component}
%\subsubsection{Sidebar component}
%\subsubsection{Model information component}
%\subsubsection{Notification tab implementation}
%\subsubsection{LIME component}

\subsection{Command-line helper tool implementation}

% #############################################
%
% Rozdział 6 - Verification
%
% #############################################
\clearpage % Rozdziały zaczynamy od nowej strony.
\section{Verification} \label{ch:verification}

\subsection{Case study: integrating Simple GTZAN model into framework}
\subsection{Unit test organization}
\subsection{Model tests, adapter test, backend tests}

% #############################################
%
% Rozdział 7 - Podsumowanie
%
% #############################################
\clearpage % Rozdziały zaczynamy od nowej strony.
\section{Summary} \label{ch:summary}

%---------------
% Bibliografia
%---------------
\cleardoublepage % Zaczynamy od nieparzystej strony
\printbibliography
\clearpage

% Wykaz symboli i skrótów.
% Pamiętaj, żeby posortować symbole alfabetycznie
% we własnym zakresie. Makro \acronymlist
% generuje właściwy tytuł sekcji, w zależności od języka.
% Makro \acronym dodaje skrót/symbol do listy,
% zapewniając podstawowe formatowanie.
\acronymlist
\acronym{EiTI}{Wydział Elektroniki i Technik Informacyjnych}
\acronym{PW}{Politechnika Warszawska}
\acronym{WEIRD}{ang. \emph{Western, Educated, Industrialized, Rich and Democratic}}
\acronym{SOTA}{State-of-art Music Models}
\acronym{LRP}{Layerwise propagation}
\texttt{JSON}{JavaScript Object Notation}
\vspace{0.8cm}

%--------------------------------------
% Spisy: rysunków, tabel, załączników
%--------------------------------------
\pagestyle{plain}

\listoffigurestoc    % Spis rysunków.
\vspace{1cm}         % vertical space
\listoftablestoc     % Spis tabel.
\vspace{1cm}         % vertical space
\listofappendicestoc % Spis załączników

%-------------
% Załączniki
%-------------

% Obrazki i tabele w załącznikach nie trafiają do spisów
\captionsetup[figure]{list=no}
\captionsetup[table]{list=no}

% Załącznik 1
\clearpage
\appendix{Nazwa załącznika 1}
\lipsum[1-3]
\begin{figure}[!h]
	\centering \includegraphics[width=0.5\linewidth]{logopw2.png}
	\caption{Obrazek w załączniku.}
\end{figure}
\lipsum[4-7]

% Załącznik 2
\clearpage
\appendix{Nazwa załącznika 2}
\lipsum[1-2]
\begin{table}[!h] \centering
    \caption{Tabela w załączniku.}
    \begin{tabular} {| c | c | r |} \hline
        Kolumna 1       & Kolumna 2 & Liczba \\ \hline\hline
        cell1           & cell2     & 60     \\ \hline
        \multicolumn{2}{|r|}{Suma:} & 123,45 \\ \hline
    \end{tabular}
\end{table}
\lipsum[3-4]

% Używając powyższych spisów jako szablonu,
% możesz dodać również swój własny wykaz,
% np. spis algorytmów.

\end{document} % Dobranoc.
