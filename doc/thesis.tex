%-----------------------------------------------
%  Engineer's & Master's Thesis Template
%  Copyleft by Artur M. Brodzki & Piotr Woźniak
%  Warsaw University of Technology, 2019-2022
%-----------------------------------------------

\documentclass[
    bindingoffset=5mm,  % Binding offset
    footnoteindent=3mm, % Footnote indent
    hyphenation=true    % Hyphenation turn on/off
]{src/wut-thesis}

%\usepackage{setspace}
%\onehalfspacing
%\frenchspacing

\graphicspath{{tex/img/}} % Katalog z obrazkami.
\addbibresource{bibliografia.bib} % Plik .bib z bibliografią

% Do debugowania czy tekst wychodzi poza margines
%\usepackage{showframe}

\usepackage{minted}
\usepackage{mdframed}
\usepackage{float}
\newtheorem{example}{Example}

\mdfdefinestyle{mintedframe}{
    innertopmargin=1mm,
    frametitlebelowskip=0pt,
    frametitleaboveskip=0pt,
    splittopskip=0pt,
    linewidth=0.75pt
}
\surroundwithmdframed[style=mintedframe]{minted}

\mdfdefinestyle{verbatimframe}{
    innertopmargin=1mm,
    frametitlebelowskip=0pt,
    frametitleaboveskip=0pt,
    splittopskip=0pt,
    linewidth=0.75pt
}
\surroundwithmdframed[style=verbatimframe]{verbatim}

%-------------------------------------------------------------
% Wybór wydziału:
%  \facultyeiti: Wydział Elektroniki i Technik Informacyjnych
%  \facultymeil: Wydział Mechaniczny Energetyki i Lotnictwa
% --
% Rodzaj pracy: \EngineerThesis, \MasterThesis
% --
% Wybór języka: \langpol, \langeng
%-------------------------------------------------------------
\facultyeiti    % Wydział Elektroniki i Technik Informacyjnych
\MasterThesis % Praca inżynierska
\langeng % Praca w języku polskim

\begin{document}

%------------------
% Strona tytułowa
%------------------
\instytut{Instytut Automatyki i Informatyki Stosowanej}
\kierunek{Computer Science}
\specjalnosc{Computer Science}
\title{
    Machine learning framework for explainable artificial intelligence models
}
% Title in English for English theses
% In English theses, you may remove this command
\engtitle{
    Machine learning framework for explainable artificial intelligence models
}
% Title in Polish for English theses
% Use it only in English theses
\poltitle{
    Machine learning framework for explainable artificial intelligence models
}
\author{Maciej Falkowski}
\album{329117}
\promotor{dr inż. Mateusz Modrzejewski}
\date{\the\year}
\maketitle

%-------------------------------------
% Streszczenie po polsku dla \langpol
% English abstract if \langeng is set
%-------------------------------------
\cleardoublepage % Zaczynamy od nieparzystej strony
\abstract
The aim of this thesis is to present a system that aims to simplify the analysis of explainable artificial intelligence (XAI) techniques in audio machine learning models.

The proposed system is a framework that integrates selected XAI techniques such as
audioLIME, SHAP (Shapley Additive explanations), and Layer-wise Relevance Propagation (LRP). The framework aims to provide a unified and extensible infrastructure for creating, managing, and visualizing model explanations.

The proposed system is structured using the Model-View-Controller (MVC) design pattern, ensuring modularity, scalability, and separation of concerns. The Model layer encapsulates operations and the machine learning models. The View layer 

defines an intuitive user interface tailored to data scientists and machine learning engineers, enabling interactive exploration of explanation outputs; and the Controller layer manages communication between the model and interface components.

% Ważne by napisać czym praca nie jesy
The aim of the thesis is not to provide 

A key contribution of this work is the formalization of design principles and integration strategies that support multimodal explanations, including both visual and auditory outputs, with a focus on interpretability and usability.

The framework includes visualization modules for displaying saliency maps, relevance heatmaps, and feature contribution plots, dynamically generated based on user queries and model outputs. In addition, user roles and interaction paradigms are defined to accommodate different levels of expertise, ensuring accessibility for both novice and expert users. The evaluation of the system demonstrates its effectiveness in improving interpretability and user understanding of complex model behaviors.

This work lays the groundwork for future research and development in human-centric AI systems, offering a flexible foundation for building transparent and trustworthy machine learning applications.
\keywords XXX, XXX, XXX

%----------------------------------------
% Streszczenie po angielsku dla \langpol
% Polish abstract if \langeng is set
%----------------------------------------
%\clearpage
%\secondabstract \kant[1-3]
%\secondkeywords XXX, XXX, XXX

\pagestyle{plain}

%--------------
% Spis treści
%--------------
\cleardoublepage % Zaczynamy od nieparzystej strony
\tableofcontents

%------------
% Rozdziały
%------------
\cleardoublepage % Zaczynamy od nieparzystej strony
\pagestyle{headings}

% #############################################
%
% Rozdział 1 - Introduction
%
% #############################################
\clearpage % Rozdziały zaczynamy od nowej strony.
\section{Introduction} \label{ch:introduction}

% Akapit z cytatem
\lipsum[1] \cite{goossens93}

% Przykładowy obrazek
\begin{figure}[!h]
    % Wyrównanie obrazka, szerokość i plik
    % Zamiast width można też użyć height, etc.
    \centering \includegraphics[width=0.5\linewidth]{logopw.png}
    % Podpis umieszczamy pod obrazkiem
    % znacznik \caption służy również do wygenerowania numeru obrazka
    \caption{Tradycyjne godło Politechniki Warszawskiej}
    % \label pozwala odwołać się do obrazka w innych miejscach za pomocą \ref
    % odwołanie \ref renderuje się jako numer obrazka,
    % dlatego zawsze najpierw używaj \caption a potem \label
    \label{fig:tradycyjne-logo-pw}
\end{figure}

% \ref wyrenderuje się jako 'Reference to image 1.1'
\lipsum[2] Reference to image \ref{fig:tradycyjne-logo-pw}.

% Lista punktowana
% Parametr label ustawia symbol punktora
\begin{itemize}
    \item Item 1:
    \begin{itemize}[label=---]
        \item item 1.1;
        \item item 1.2;
    \end{itemize}
    \item Item 2;
    \item Item 3.
\end{itemize}

\lipsum[3]

% Lista numerowana w formacie 1.a).ii
% Tutaj również można stosować \label
\begin{enumerate}
    \item Item 1:
    \begin{enumerate}
        \item item 1.1;
        \item item 1.2:
        \begin{enumerate}
            \item item 1.2.1;
            \item item 1.2.2;
        \end{enumerate}
        \item item 1.3;
    \end{enumerate}
    \item Item 2;
    \item Item 3.
\end{enumerate}

% Przypis dolny \footnote
\lipsum[4] Lorem ipsum dolor sit amet\footnote{Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat.}, consectetur adipiscing elit.

% Przykładowa tabela: wyśrodkowana i renderowana
% w miejscu wstawienia: !h = !h[ere]
% Domyślnie tabele trafiają na górę strony
\begin{table}[!h] \centering
    % Podpis tabeli umieszczamy od góry
    \caption{Przykładowa tabela.}
    \label{tab:tabela1}

    % Tabela z trzema kolumnami:
    % dwie wyrównanie do środka [c], a ostatnia do prawej [r]
    % szerokość kolumn automatyczna (równa szerokości tekstu)
    \begin{tabular}{| c | c | r |} \hline
        Kolumna 1       & Kolumna 2 & Liczba \\ \hline\hline
        cell1           & cell2     & 60     \\ \hline
        cell4           & cell5     & 43     \\ \hline
        cell7           & cell8     & 20,45  \\ \hline
        % Komórka o szerokości dwóch kolumn, wyrównana do prawej
        % Przypisy dolne w tabelach wstawiamy przez \tablefootnote
        \multicolumn{2}{|r|}{Suma\tablefootnote{Table footnote.}} & 123,45 \\ \hline
    \end{tabular}

\end{table}

Lorem ipsum dolor sit amet.

% #############################################
%
% Rozdział 2 - Analiza problemu
%
% #############################################
\clearpage % Rozdziały zaczynamy od nowej strony.
\section{Problem analysis} \label{ch:probAnalysis}

This chapter provides an overview of terminology and methods used in the thesis,
which describes essentials of machine learning explanations, description of explanation methods used in the thesis which are audioLIME, LRP, SHAP, and software engineering principles used for designing a framework for audio machine learning explanations.

\subsection{Why explanation framework for audio - the problem}
\subsubsection{Why explanation framework for audio - the problem}

\subsection{Similar solutions}

\subsection{Selection of methodology - overview of framework, monolithic UI etc.}

\subsection{Framework definition}
\subsubsection{Definition}
\subsubsection{Modularity}
\subsubsection{Dependency injection}

\subsection{Definition of user}

\subsection{Definition of ML explanation}
\subsubsection{Locality-awareness}
\subsubsection{Model-agnostic}

\subsection{Audio processing}
\subsubsection{Waveform representation}
\subsubsection{Mel-spectogram}

\subsection{Model explanation}
\subsubsection{definition}
\subsubsection{Locality-awareness}

\subsection{Selection of explanation methods for framework}
\subsubsection{Criteria - interpretability, attribution, model-agnostic}
\subsubsection{AudioLIME}
\subsubsection{Shapley values method}
\subsubsection{Layerwise propagation}

\subsection{Selection of model for integration}
\subsubsection{Criteria - practicality}
\subsubsection{State-of-art Music Models}
\subsubsection{Paans}
\subsubsection{Paast}
\subsubsection{Handmade Gtzan}

\subsection{ML Explanation framework overview}
\subsubsection{Framework components - library, UI, terminal command}

\subsection{Visualizing ML Explanation framework overview}

\subsection{Model-View controller}
\subsubsection{Architecture of Model-View Controller}
\subsubsection{Characteristic of Model, View and Controller}
\subsubsection{Separation of operations on data and visualization}

% #############################################
%
% Rozdział 3 - Requirements and tools (może Framework requirements?)
%
% #############################################
\clearpage % Rozdziały zaczynamy od nowej strony.
\section{Requirements and tools} \label{ch:reqrTools}

        This chapter defines and formalizes requirements that the project must actualize
    to meet the objective of the thesis, including software and behavioral requirements.
    The chapter starts with a definition of functional and non-functional requirements,
    followed by an overview of software requirements and tools used in the thesis.

\subsection{Functional requirements}

    The functional requirements seek to define how a framework should behave to its user.
    For clarity the requirements are divided based on the software component of the framework which
    in framework's case are library, user web interface, and terminal helper tool.

% Wymagania interfejsu, backend serwera, UI
\subsubsection{Library application programming interface requirements}
    \begin{enumerate}

    \item \textbf{Provide user model injection}

        The library API must enable users to create adapters for their classes allowing them to inject operations on
    their data into the framework. Users may implement custom model adapters by extending the provided base
    classes. This enables integration of various audio model architectures with the explanation
    framework.

    \item \textbf{Provide explanation interface for model adapters}

        The library API must offer base classes for implementing a given explanation method.
    Each adapter type must define specific methods required for the corresponding explanation algorithm,
    including LIME, SHAP, or LRP, ensuring a consistent interface for different explanation methods.

    \item \textbf{Explanation Method Selection}

        The library API must offer users the ability to choose which explanation methods are displayed in the view.
    Users can select from available explainers including LIME, SHAP, and LRP through library API or through
    command-line arguments in case when using a helper tool. This allows users to focus on specific explanation
    approaches relevant to their use case.

    \item \textbf{Support necessary audio format}

        The library API must support user audio input provided in \texttt{.wav} and \texttt{.mp4} formats.
    Audio should be automatically converted to appropriate tensor formats for model processing.

    \item \textbf{Provide interface for view classes}

        The library API must offer a base interface for implementing views which will fulfill
    the requirement of modularity and allow a system to support multiple view types.

    \item \textbf{Context Management}

        The library API must define a context that serves to store and save the current explanation progress.
    The context class manages working directories, file operations, and explanation state throughout the process.
    Context provides centralized access to resources and maintains consistency across different explanation phases.

    \item \textbf{Interface for prediction class information}

        The library should offer an interface enabling users to inject prediction class information.
    This information is essential for proper explanation interpretation and visualization.
    The system should support label retrieval dynamically depending on whether the user provided
    support for their user-defined model adapters.

    \item \textbf{Support for selected explanation methods}

        The library API must provide explanation methods selected for the thesis, such as LIME, SHAP, and LRP.
    These methods should be implemented as classes, and they also serve as controllers within
    the Model-View-Controller pattern and coordinate between model adapters, explanation algorithms, and view components. They encapsulate the complete explanation workflow from input processing to result visualization.

    \item \textbf{Support for web interface view}

        The library API must define web server view classes that manage file serving and web-based user interface.
    Web server components handle HTTP requests and serve explanation results through a user interface.

    \item \textbf{Ensure persistent result storage}

        The library API must ensure persistent storage of user results on disk to prevent
    data loss. The context system should provide this by saving explanation artifacts to
    the working directory. This will enable users to archive explanation outputs across 
    multiple sessions.
    
    \end{enumerate}

\subsubsection{User web interface requirements}
    \begin{enumerate}
    %\vspace{\baselineskip}
    \item \textbf{Separate tab for each explanation result}

            The user interface must aggregate the results of each explanation method in separate tabs to organize
        outcomes and enable switching between them. Each explanation method, which is LIME, SHAP, or LRP,
        should get its dedicated tab. This should allow users to easily navigate different explanation approaches
        to compare results. The sidebar should provide a structured view of all generated explanations in a single
        interface and allow you to switch between them.

    \item \textbf{Display original audio playback}

        The user interface must display the original audio track that serves as input for explanations across all
    explanation methods. The interface must enable audio playback functionality, including play/pause controls and
    waveform visualization. Users can listen to the original audio while examining explanation results for better
    context understanding. The waveform display provides a visual representation of the audio signal structure.

    \item \textbf{Visualize LIME explanation result}

        The user interface must display LIME explanation result as playable audio.
    Users should be able to listen to specific audio segments that contributed most significantly
    to the model's prediction. This enables an intuitive understanding of which temporal parts of
    the audio influenced the model's decision. The width of the explained audio visualization
    should be aligned with the original audio.

    \item \textbf{Provide version information}

        The user interface must display information about the library version so that users may verify which
    version of a library they are currently using. Such information may prove to be useful,
    for example, for troubleshooting.

    \item \textbf{Display notification and error information}

        The user interface must display notifications about errors or other information in a dedicated information
    panel. The notification system provides user feedback for processing status, errors, warnings,
    and completion messages. Users receive clear communication about the system state and any issues that
    require attention. The dedicated panel ensures important messages are prominently displayed without
    disrupting the main workflow.

    \item \textbf{Visualize attribution intensity}

        The user interface must show plot of attribution intensity of user's input audio
    for both SHAP and LIME explanations. The attribution scores given to various audio input segments are displayed in these plots. This enables users to determine which audio signal regions had the biggest impact on the model's prediction.

    \item \textbf{Display of user's input overlayed with attribution}

        The user interface must display attribution overlaid on user's input for both SHAP and LIME explanations.
    Attribution values are visualized as color heatmaps on the user's spectrogram which enables a user to
    understand which frequency components at a given time interval influenced the model's decision.
    This method works very well when the input provided to the model is a spectrogram.

    \item \textbf{Display prediction classes of user's model}

        The user interface must display optional model label descriptions when provided by the user's model adapter.
    The interpretability of explanation visualizations is improved by label information.

    \end{enumerate}

\subsubsection{Terminal application requirements}
    Framework must provide a terminal-application tool for launching supported models on framework's explanation method with input provided by the user. The tool then will implement a typical usage scenario:
    \begin{enumerate}
        \item User input is converted from a waveform input into model's type which is either tensor of input samples or spectrogram type.
        \item The tool defines a necessary model adapter,
    \end{enumerate}

    \begin{enumerate}

    \item \textbf{Provide selection of one or more explanation method}

        The application must enable users to select one or more explanation methods offered by the framework which are LIME, SHAP, or LRP.

    \item \textbf{Provide selection of audio model}

            The application must enable users to select from models implemented within the framework that they
        intend to use. 

    \item \textbf{Provide selection of visualization method}

        The application must enable users to select the visualization method implemented in the framework.
    Users can choose between web-based visualization and disabled visualization.

    \item \textbf{Provide selection of working directory}

    The application must enable users to select a folder as the working directory or create a default when not provided by the user.

    \end{enumerate}

\subsection{Non-functional requirements}

    The implementation of an audio XAI framework must meet several criteria
    top ensure proper behavior for the user and quality criteria.
    The most important criteria are modularity, usability, and persistency.

\begin{description}
    \item \textbf{Modularity}

         The project thesis aims to provide a general and extensible audio explanation framework. The system must be 
    designed with a modular structure, where key components such as explanation methods, model adapters, and view renderers
    are implemented as independent modules. For that, the system must adhere to the pattern principles of Model-View-
    Controller architecture as discussed in <Sec. TODO> This modularity allows for the seamless integration of new 
    functionalities, such as adding additional explanation algorithms or supporting new audio models, without requiring 
    modifications to the core of the system.

    \item \textbf{Reliability}

        The system must behave stably and predictably during normal operation. During regular operation, the system has to
    display stable and predictable behavior. The user interface, audio processing pipelines, and explanation methods must
    all gracefully handle runtime errors and invalid inputs. Errors must be properly logged, and informative feedback must
    be sent to the user without crashing. To avoid data loss, intermediate and final outputs need to be saved consistently.

    \item \textbf{Usability}

        The framework library and web user interface must follow intuitive design principles, including consistent
    navigation, clear labeling, and visual clarity of explanation results. The use of separate tabs for different 
    explanation methods ensures that users can focus on one explanation at a time while easily switching between views. 
    Notifications and status indicators must be visible and should inform a user about the behavior of the interface. In 
    addition, the command-line application helper tool must be a fast way of testing the library implementation and environment setup.

\end{description}

\subsection{Tools specification}
\begin{description}
\item \textbf{PyTorch}

A comprehensive open-source machine learning framework that provides exceptional flexibility for building and training neural networks with dynamic computational graphs. PyTorch offers seamless GPU acceleration capabilities enabling efficient training of complex deep learning models on large datasets. The framework provides extensive libraries of pre-built components and optimizers that accelerate development while maintaining a pythonic interface. PyTorch has become the preferred framework for research due to its intuitive debugging experience and strong community support.

\item \textbf{librosa}

A specialized Python library for music and audio signal processing that provides comprehensive tools for analyzing sound data through various time-frequency transforms. Librosa offers advanced capabilities for rhythm analysis, beat detection, and feature extraction of key acoustic characteristics commonly used in machine learning pipelines. The library integrates smoothly with numerical computing libraries while supporting various audio formats with built-in resampling capabilities. Librosa emphasizes reproducible research with transparent implementations of audio algorithms complemented by excellent documentation.

\item \textbf{torchaudio}

A domain-specific library built on PyTorch that provides GPU-accelerated tools for audio processing tasks in deep learning applications. TorchAudio offers seamless integration with PyTorch's autograd system, enabling gradient-based training with audio feature extractors as differentiable components. The library includes specialized audio augmentation techniques and pre-trained models for common audio tasks with a consistent tensor-based API. TorchAudio ensures compatibility with PyTorch's ecosystem and is actively maintained with regular updates incorporating state-of-the-art techniques.

\item \textbf{pytest}

A sophisticated testing framework for Python that emphasizes simplicity with a minimalist syntax for writing tests and a powerful fixture system for managing dependencies. Pytest's parameterization features enable running tests with multiple inputs while providing detailed assertion introspection to quickly identify issues. The framework's plugin architecture has fostered a rich ecosystem of extensions for specialized testing needs including coverage analysis. Pytest supports both unit and functional testing with automatic test discovery and comprehensive reporting features.

\item \textbf{matplotlib}

A comprehensive data visualization library for Python that has become the standard for creating publication-quality figures and interactive visualizations. Matplotlib offers exceptional flexibility through its object-oriented API, allowing precise control over every aspect of plots for creating complex custom visualizations. The library supports an extensive range of plot types from basic line graphs to specialized visualizations suitable for diverse data representation needs. Matplotlib integrates seamlessly with NumPy and pandas while providing robust support for mathematical expressions through LaTeX rendering.

\item \textbf{captum}

An interpretability library built specifically for PyTorch that implements state-of-the-art algorithms for explaining decisions made by deep learning models. Captum provides unified implementations of gradient-based attribution methods that reveal feature importance across various model architectures at multiple granularities. The library implements advanced visualization techniques for different data modalities, rendering attributions as heatmaps for images and waveforms for audio. Captum's attribution methods support batch processing and GPU acceleration with a consistent API that works across different model architectures.

\item \textbf{React}

A declarative JavaScript library that has revolutionized user interface development through its component-based architecture and efficient virtual DOM rendering system. React promotes unidirectional data flow that makes application state changes predictable while its JSX syntax combines JavaScript with HTML-like templates for creating reusable components. The library's robust ecosystem includes state management solutions, routing libraries, and testing frameworks that address common development challenges. React's composition-focused design encourages creation of small, focused components that can be combined to build complex interfaces while promoting code reuse.
\end{description}

% #############################################
%
% Rozdział 4 - External specification
%
% #############################################
\clearpage % Rozdziały zaczynamy od nowej strony.
\section{External specification} \label{ch:externalSpec}

\subsection{Installation process overview}
\subsubsection{Installation steps}

\subsection{Command-line tool for simple explanations}

\subsection{Web interface for explanation}
\subsubsection{Initalizing web interface}
\subsubsection{Displaying LIME results}
\subsubsection{Displaying LRP results}
\subsubsection{Displaying SHAP results}
\subsubsection{Displaying software warning}
\subsubsection{Version information}

% #############################################
%
% Rozdział 5 - Framework implementation
%
% #############################################
\clearpage % Rozdziały zaczynamy od nowej strony.
\section{Framework implementation} \label{ch:implementation}

    The following chapter contains an overview of the architecture and implementation details of the explanation framework. It briefly discusses each of the system's components by providing
    a walk-through of each step of the framework's explanation pipeline.

\subsection{Software architecture overview}

    The architecture of the project consists of three main components that are library, web interface, and command-line helper script.
    These component implement all steps of a full-pipeline from prereprocessing
    user's input up to visualizing explanation results as discussed in
    %\ref{fig:PipelineArchitecture}. TODO

\begin{enumerate}
    \item \textbf{Library} - provides a main logic and implementation. It is interfacing directly
        with a user and provides a necessary tools for execution of explanation. This includes   interfaces for creation of adapters for user's models, logic implementing supported explanation types, visualization of explanation that include frontend web interface, and helper utilities.

    \item \textbf{Web interface} - Defines a main visual view for observation of explanations' results. It is composed from two parts which the first is a backend server that server's the explanation results to the frontend part through HTTP protocol. The frontend part then requests required data from the backend server and visualizes it in the form of browser page.

    \item \textbf{Command-line helper script} - It is a toolchain's helper script and serves a purpose of quickly launching a typical usage type of the library which is loading an input audio file and then launching a chosen set of explanations on the chosen library's provided model.
\end{enumerate}

The communication process between user application and framework is shown in \ref{fig:CommunicationArchitecture}.

\begin{figure}[h!] % TODO: h! musi być wyłączone
    \centering
    \includegraphics[width=15cm]{comm.jpg}
    \caption{Communication scheme between user application and frontend.}
    \label{fig:CommunicationArchitecture}
\end{figure}

\subsection{Project structure}

    The project’s source code is grouped in multiple directories grouping similar implementations. They contain an implementation of each of the framework’s pipeline phases
    and unit test definitions for them.

\begin{description}
	\item \textbf{audioLIME/} - Contains implementation of LIME explanation method adapted for audio data.
	\item \textbf{AudioLoader/} - Provides utilities for loading and preprocessing audio files from various formats.
	\item \textbf{Explainers/} - Contains base explainer classes and LIME explainer implementation.
	\item \textbf{gtzan\_lime\_expl/} - Stores LIME explanation results and outputs for GTZAN model experiments.
	\item \textbf{inference.py} - Main command-line entry point for running explanations on audio models.
	\item \textbf{Interfaces/} - Defines abstract base classes and interfaces for adapters, explainers, and views.
	\item \textbf{LRPExplainer/} - Contains Layer-wise Relevance Propagation explainer implementation.
	\item \textbf{model\_adapters/} - Implements adapter classes for integrating different audio models with the framework.
	\item \textbf{models/} - Contains pre-trained model files and checkpoints for supported audio models.
	\item \textbf{paans\_shap\_expl/} - Stores SHAP explanation results and outputs for PAANS model experiments.
	\item \textbf{pretrained\_models/} - Additional directory for storing pre-trained model weights and configurations.
	\item \textbf{pylibxai\_context/} - Implements context management for storing explanation state and working directories.
	\item \textbf{pylibxai\_server/} - Contains web server implementation for serving explanation results through HTTP.
	\item \textbf{pylibxai-ui/} - Frontend React application providing web-based user interface for visualization.
	\item \textbf{ShapExplainer/} - Contains SHAP (Shapley Additive Explanations) explainer implementation.
	\item \textbf{utils.py} - Provides utility functions for path management and common operations.
\end{description}

\subsection{Model-View-Controller implementation overview}
% Class diagram

\subsection{Model adapter interfaces}

\subsection{Model adapter implementation}
\subsubsection{GtzanCNN model adapter}
\subsubsection{SOTA model adapter}
\subsubsection{Paans model adapter}

\subsection{Explainer classes implementation}
\subsubsection{LIME explainer}
\subsubsection{SHAP explainer}
\subsubsection{LRP explainer}

\subsection{Context class definition}

\subsection{View class definition}
\subsubsection{Web view class}
\subsubsection{LIME explainer}

\subsection{Web frontend implementation}
\subsubsection{File server backend}
\subsubsection{Frontend UI class}

\subsection{Frontend web interface view implementation}
\subsubsection{Main component}
\subsubsection{Sidebar component}
\subsubsection{Model information component}
\subsubsection{Notification tab implementation}
\subsubsection{LIME component}

\subsection{Command-line helper tool implementation}

% #############################################
%
% Rozdział 6 - Verification
%
% #############################################
\clearpage % Rozdziały zaczynamy od nowej strony.
\section{Verification} \label{ch:verification}

\subsection{Case study: integrating Simple GTZAN model into framework}
\subsection{Unit test organization}
\subsection{Model tests, adapter test, backend tests}

\begin{figure}%[h!]
\begin{minted}[numbersep=12pt, fontsize=\footnotesize, xleftmargin=12pt, linenos, mathescape]{py}
class GtzanAdapter(LrpAdapter, LimeAdapter, ShapAdapter, ModelLabelProvider):
    def __init__(self, model_path, device='cuda'):
        self.predictor = GtzanPredictor(model_path, device)
        self.predictor.load_model()
        self.device = device
        self.target_length = 22050 * 30  # Expected audio length

    def pad_or_truncate_waveform(self, wav, target_len):
        current_len = wav.shape[-1]
        if current_len < target_len:
            pad_amt = target_len - current_len
            wav = F.pad(wav, (0, pad_amt))  # pad end with zeros
        elif current_len > target_len:
            wav = wav[:, :target_len]  # truncate
        return wav
    
    def get_label_mapping(self) -> Dict[int, str]:
        return self.predictor.label_to_id
\end{minted}
\caption{Compiler's recursive compilation scheme of the abstract syntax tree.}
\label{fig:RecursiveCompilation}
\end{figure}

This is sample code; pay attention to this part

\mintinline{py}{def foo(self, wav, target_len)},
the full code presented at \ref{fig:RecursiveCompilation}

\begin{figure}%[h]
\begin{verbatim}
assignment_stmt ::=  (target_list "=")+ (starred_expression |
                                         yield_expression)
target_list     ::=  target ("," target)* [","]
target          ::=  identifier
                     | "(" [target_list] ")"
                     | "[" [target_list] "]"
                     | attributeref
                     | subscription
                     | slicing
                     | "*" target
\end{verbatim}
\caption{The Python's eBNF notation of assignment expression.}
\label{fig:PythonExampleRule}
\end{figure}

% #############################################
%
% Rozdział 7 - Podsumowanie
%
% #############################################
\clearpage % Rozdziały zaczynamy od nowej strony.
\section{Summary} \label{ch:summary}

%---------------
% Bibliografia
%---------------
\cleardoublepage % Zaczynamy od nieparzystej strony
\printbibliography
\clearpage

% Wykaz symboli i skrótów.
% Pamiętaj, żeby posortować symbole alfabetycznie
% we własnym zakresie. Makro \acronymlist
% generuje właściwy tytuł sekcji, w zależności od języka.
% Makro \acronym dodaje skrót/symbol do listy,
% zapewniając podstawowe formatowanie.
\acronymlist
\acronym{EiTI}{Wydział Elektroniki i Technik Informacyjnych}
\acronym{PW}{Politechnika Warszawska}
\acronym{WEIRD}{ang. \emph{Western, Educated, Industrialized, Rich and Democratic}}
\acronym{SOTA}{State-of-art Music Models}
\acronym{LRP}{Layerwise propagation}
\vspace{0.8cm}

%--------------------------------------
% Spisy: rysunków, tabel, załączników
%--------------------------------------
\pagestyle{plain}

\listoffigurestoc    % Spis rysunków.
\vspace{1cm}         % vertical space
\listoftablestoc     % Spis tabel.
\vspace{1cm}         % vertical space
\listofappendicestoc % Spis załączników

%-------------
% Załączniki
%-------------

% Obrazki i tabele w załącznikach nie trafiają do spisów
\captionsetup[figure]{list=no}
\captionsetup[table]{list=no}

% Załącznik 1
\clearpage
\appendix{Nazwa załącznika 1}
\lipsum[1-3]
\begin{figure}[!h]
	\centering \includegraphics[width=0.5\linewidth]{logopw2.png}
	\caption{Obrazek w załączniku.}
\end{figure}
\lipsum[4-7]

% Załącznik 2
\clearpage
\appendix{Nazwa załącznika 2}
\lipsum[1-2]
\begin{table}[!h] \centering
    \caption{Tabela w załączniku.}
    \begin{tabular} {| c | c | r |} \hline
        Kolumna 1       & Kolumna 2 & Liczba \\ \hline\hline
        cell1           & cell2     & 60     \\ \hline
        \multicolumn{2}{|r|}{Suma:} & 123,45 \\ \hline
    \end{tabular}
\end{table}
\lipsum[3-4]

% Używając powyższych spisów jako szablonu,
% możesz dodać również swój własny wykaz,
% np. spis algorytmów.

\end{document} % Dobranoc.
